## Определение тональности текста

### Стек инструментов

Библиотеки nltk и spacy.
Предобработка текстов, лемматизация и векторизация.
Модели sklearn и BERT.

### Вводные данные

Интернет магазин создает сервис для анализа комментариев пользователей. Модель машинного обучения позволит в автоматическом режиме отправлять нецензурные комментарии на модерацию.
Для обучение моделей имеются размеченные данные с комментариями и ручным указанием тональности текста.

### Цель
Обучить модель классифицировать комментарии на позитивные и негативные.

#### *Дополнительно*

Разобраться в работе модели BERT.

## Структура проекта  

1. Загрузить и подготовите данные. Применить чистку текста, лематизацию и векторизацию.
2. Обучить модели sklearn и BERT.
3. Проанализировать выводы.

### Общий вывод

В первом работе по работе с текстом перед нами стояла задача создать модель, способную отличать токсичные комментарии от обычных, и делать это с показателем метрики f1 >= 0.75.

На первом этапе было произведено знакомство с даннымы, указано отсутсвие пропусков и выявлена общая информация о датасете.
Далее последовала предобработка с лемматизацией, удалением ненужных символов и переводом комментариев в матрицы tf-idf.

На втором шаге были протестированы 4 модели - три представителя линейных классификаторов и ансамбль градиентного спуска. На тестовой выборке все модели показали допустимый результат. Лучший показатель у SGDClassifier - 0.79 на тестовой выборке.

Несмотря на "проходимость" результата, продолжаю искать новые пути и методы для улучшения качества предсказания.

